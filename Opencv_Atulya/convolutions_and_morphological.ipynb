{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>cv2.getStructuringElement(type, ksize)</b> outputs a kernel matrix of required <i>`@type`</i> and <i>`@size`</i>\n",
    ">\n",
    ">the below cell is self explanatory, run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 0]] \n",
      "\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]] \n",
      "\n",
      "[[0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernelellip = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,3))\n",
    "kernelrect = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "kernelcross = cv2.getStructuringElement(cv2.MORPH_CROSS, (5,5))\n",
    "print(kernelellip,\"\\n\")\n",
    "print(kernelrect,\"\\n\")\n",
    "print(kernelcross,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"assets//images//hello.jpg\",0)\n",
    "cv2.imshow(\"hello\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>cv2.dilate(img, structuringkernel, iterations)</b> widens the white regions of an image\n",
    ">\n",
    "><i>`@structuringkernel`</i> defines the way the neighbouring pixels will be used in central pixel calculation\n",
    ">\n",
    "><i>`@iterations`</i> the no. of times the operation is done\n",
    ">\n",
    "><b>cv2.erode()</b> works just the opposite i.e. it narrows the white regions. it has ecxactly the same parameters as cv2.dilate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilate = cv2.dilate(img,kernelrect,iterations=3)\n",
    "erode = cv2.erode(img,kernelrect,iterations=3)\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.imshow(\"dilate\",dilate)\n",
    "cv2.imshow(\"erode\",erode)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>cv2.morphologyEx(img, operation, structuringkernel)</b> used to do some basic morphological operations with the image. what are these operations will be explained soon in the below cells. here we will perform 5 operations\n",
    ">- `opening` erosion followed by dilation.\n",
    ">- `closing` opposite of opening, dilation followed by erosion.\n",
    ">- `morphological gradient` is the difference between a dilation and erosion.\n",
    ">- `top hat` is the difference between the original (grayscale/single channel) input image and the opening.\n",
    ">- `black hat` is the difference between the closing and the original (grayscale/single channel) input image.\n",
    ">\n",
    ">[morphological operations](https://docs.opencv.org/4.x/d9/d61/tutorial_py_morphological_ops.html) is an amazing explanation of this operations with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = cv2.imread(\"assets//images//hello_noise_white.jpg\",0)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "opening = cv2.morphologyEx(white_noise,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow(\"original\",white_noise)\n",
    "cv2.imshow(\"opening\",opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise = cv2.imread(\"assets//images//hello_noise_black.jpg\",0)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "closing = cv2.morphologyEx(black_noise,cv2.MORPH_CLOSE,kernel)\n",
    "cv2.imshow(\"original\",black_noise)\n",
    "cv2.imshow(\"closing\",closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"assets//images//hello.jpg\",0)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "grad = cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernel)\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.imshow(\"morphological gradient\",grad)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise = cv2.imread(\"assets//images//hello_noise_white.jpg\",0)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "tophat = cv2.morphologyEx(white_noise,cv2.MORPH_TOPHAT,kernel)\n",
    "cv2.imshow(\"original\",white_noise)\n",
    "cv2.imshow(\"tophat\",tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_noise = cv2.imread(\"assets//images//hello_noise_black.jpg\",0)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (11,11))\n",
    "tophat = cv2.morphologyEx(black_noise,cv2.MORPH_BLACKHAT,kernel)\n",
    "cv2.imshow(\"original\",black_noise)\n",
    "cv2.imshow(\"tophat\",tophat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>Convolutions</b>\n",
    ">\n",
    ">![convolutions](assets//images/convolutions.gif)\n",
    ">![convolutions with padding](assets//images/convolutions%20with%20padding.gif)\n",
    ">\n",
    ">for more reading, refer [this](https://pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><b>cv2.filter2D(img, ddepth, kernel)</b> use to convolve a <i>`@kernel`</i> with the <i>`@img`</i>\n",
    ">\n",
    "><i>`@ddepth`</i> depth of output image. set it to -1 to so that depth of output image becomes equal to depth of input image\n",
    ">\n",
    ">for knowing more about its parameters read [doc.py](assets//doc.py) in the assets folder, and search the function in the py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "img = cv2.imread(\"assets//images//lenna.jpg\")\n",
    "sharp = cv2.filter2D(img, -1, kernel)\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.imshow(\"sharp\",sharp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">here are some example kernels\n",
    ">\n",
    ">![kernels](assets//images/examples%20kernels.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1acc9de6222209ae68b885bb20af33354269db69f65eec804e0118f54b29f529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pythonX')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
